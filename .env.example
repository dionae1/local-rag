# Available LLM models are 'gemini' for gemini-2.5-flash and 'ollama' for any ollama model running locally
LLM_MODEL=gemini

# Optional if you want to use Gemini
GEMINI_API_KEY=your-gemini-key

# Database option: 'sqlite' or 'postgres' - if you choose 'postgres', make sure to run the container
DB_OPTION=sqlite